{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pip Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: convokit in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (3.0.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (3.8.4)\n",
      "Requirement already satisfied: pandas>=0.23.4 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (2.2.0)\n",
      "Requirement already satisfied: msgpack-numpy>=0.4.3.2 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (0.4.8)\n",
      "Requirement already satisfied: spacy>=2.3.5 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (3.7.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (1.4.2)\n",
      "Requirement already satisfied: nltk>=3.4 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (3.8.1)\n",
      "Requirement already satisfied: dill>=0.2.9 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (0.3.8)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (1.4.0)\n",
      "Requirement already satisfied: clean-text>=0.6.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (0.6.0)\n",
      "Requirement already satisfied: unidecode>=1.1.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (1.3.8)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (4.66.2)\n",
      "Requirement already satisfied: pymongo>=4.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (4.7.2)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (6.0.1)\n",
      "Requirement already satisfied: dnspython>=1.16.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from convokit) (2.6.1)\n",
      "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from clean-text>=0.6.0->convokit) (1.7.0)\n",
      "Requirement already satisfied: ftfy<7.0,>=6.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from clean-text>=0.6.0->convokit) (6.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->convokit) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->convokit) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->convokit) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->convokit) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->convokit) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->convokit) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->convokit) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->convokit) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.0.0->convokit) (2.8.2)\n",
      "Requirement already satisfied: msgpack>=0.5.2 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from msgpack-numpy>=0.4.3.2->convokit) (1.0.8)\n",
      "Requirement already satisfied: click in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from nltk>=3.4->convokit) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from nltk>=3.4->convokit) (2024.5.15)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=0.23.4->convokit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=0.23.4->convokit) (2023.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn>=0.20.0->convokit) (3.5.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (6.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (2.6.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (69.2.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from spacy>=2.3.5->convokit) (3.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.64.0->convokit) (0.4.6)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from ftfy<7.0,>=6.0->clean-text>=0.6.0->convokit) (0.2.13)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.3.5->convokit) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (4.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->convokit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.3.5->convokit) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.3.5->convokit) (0.1.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from weasel<0.4.0,>=0.1.0->spacy>=2.3.5->convokit) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->spacy>=2.3.5->convokit) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.3.5->convokit) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from seaborn) (1.26.3)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from seaborn) (2.2.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.2->seaborn) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\joda\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"C:\\Users\\joda\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconvokit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Corpus, download\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\convokit\\__init__.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoordination\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolitenessStrategies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvokitPipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\convokit\\politenessStrategies\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolitenessStrategies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\convokit\\politenessStrategies\\politenessStrategies.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconvokit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Corpus, Utterance, Speaker\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconvokit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoliteness_collections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoliteness_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoliteness_strategies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     get_politeness_strategy_features,\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[0;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\errors.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\\compat.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Helpers for Python and platform compatibility.\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copy_array\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcPickle\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\__init__.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregistry\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\config.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconfection\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VARIABLE_RE, Config, ConfigValidationError, Promise\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Decorator\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mregistry\u001b[39;00m(confection\u001b[38;5;241m.\u001b[39mregistry):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     optimizers: Decorator \u001b[38;5;241m=\u001b[39m catalogue\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthinc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m, entry_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\types.py:25\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     Any,\n\u001b[0;32m      6\u001b[0m     Callable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     overload,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cupy, has_cupy\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_cupy:\n\u001b[0;32m     28\u001b[0m     get_array_module \u001b[38;5;241m=\u001b[39m cupy\u001b[38;5;241m.\u001b[39mget_array_module\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thinc\\compat.py:35\u001b[0m\n\u001b[0;32m     31\u001b[0m     has_cupy_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdlpack\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     has_torch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\__init__.py:141\u001b[0m\n\u001b[0;32m    139\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    140\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 141\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    143\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\joda\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "from convokit import Corpus, download\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of the movie-corpus\n",
    "corpus = Corpus(filename=download(\"movie-corpus\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative Data Anlyses\n",
    "\n",
    "We afe the data in pandas dataframes and explore it. We drop data that is not labeled correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = corpus.get_utterances_dataframe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = corpus.get_conversations_dataframe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = corpus.get_speakers_dataframe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters['meta.gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters['meta.gender'] = characters['meta.gender'].str.lower()\n",
    "characters['meta.gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(characters['meta.gender'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_drop = characters[characters['meta.gender'] == '?'].index\n",
    "characters = characters.drop(rows_to_drop)\n",
    "characters['meta.gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preperation of the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the dataframes\n",
    "merged_df = pd.merge(utterances, conversations, left_on='conversation_id', right_on='id', suffixes=('_utterance', '_conversation'))\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(merged_df, characters, left_on='speaker', right_on='id', how='left', suffixes=('_merged', '_character'))\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['speaker'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column with the number of lines spoken by each character\n",
    "final_df['line_count'] = final_df.groupby('speaker')['speaker'].transform('size')\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with missing values in the 'meta.gender' column\n",
    "final_df = final_df.dropna(subset=['meta.gender'])\n",
    "final_df['meta.gender'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['meta.gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant / empty columns\n",
    "final_df = final_df.drop(columns=['timestamp'])\n",
    "final_df = final_df.drop(columns=['reply_to'])\n",
    "print(final_df.isnull().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['meta.credit_pos'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label empty values as '10+'\n",
    "final_df['meta.credit_pos'] = final_df['meta.credit_pos'].apply(lambda p: '10+' if not p in ['1', '2', '3', '4', '5', '6', '7', '8', '9'] else p) \n",
    "final_df['meta.credit_pos'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column with the length of lines\n",
    "final_df['lineLength'] = final_df['text'].str.len()             \n",
    "final_df['wordCountLine'] = final_df['text'].str.count(' ') + 1 \n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['medianLineLength'] = final_df.groupby('speaker')['lineLength'].transform('median')\n",
    "final_df['medianWordCountLine'] = final_df.groupby('speaker')['wordCountLine'].transform('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['meta.rating'] = pd.to_numeric(final_df['meta.rating'], errors='coerce')\n",
    "final_df['meta.votes'] = pd.to_numeric(final_df['meta.votes'], errors='coerce')\n",
    "final_df['meta.release_year'] = pd.to_numeric(final_df['meta.release_year'], errors='coerce').astype('Int64')\n",
    "\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting Labeling\n",
    "m_rows = final_df[final_df['meta.gender'] == 'm']\n",
    "\n",
    "non_m_rows = final_df[final_df['meta.gender'] != 'm']\n",
    "\n",
    "m_rows_sampled = m_rows.sample(n=70768, random_state=42)\n",
    "\n",
    "final_df = pd.concat([m_rows_sampled, non_m_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['meta.gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot gender differences in line count and word count per line\n",
    "gender_stats = final_df.groupby('meta.gender').agg(\n",
    "    total_lines=('line_count', 'sum'),\n",
    "    avg_word_count=('wordCountLine', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "print(gender_stats)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "axes[0].bar(gender_stats['meta.gender'], gender_stats['total_lines'], color=['blue', 'pink'])\n",
    "axes[0].set_title('Total Number of Lines per Gender')\n",
    "axes[0].set_xlabel('Gender')\n",
    "axes[0].set_ylabel('Total Number of Lines')\n",
    "\n",
    "axes[1].bar(gender_stats['meta.gender'], gender_stats['avg_word_count'], color=['blue', 'pink'])\n",
    "axes[1].set_title('Average Word Count per Line per Gender')\n",
    "axes[1].set_xlabel('Gender')\n",
    "axes[1].set_ylabel('Average Word Count per Line')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot gender differences in line length\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='meta.gender', y='lineLength', data=final_df, palette={\"m\": \"pink\", \"f\": \"blue\"})\n",
    "plt.title('Line Length Distribution by Gender', fontsize=16)\n",
    "plt.xlabel('Gender', fontsize=14)\n",
    "plt.ylabel('Line Length', fontsize=14)\n",
    "plt.ylim(0, 500)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the count of characters\n",
    "posCredit_gender_counts = final_df.groupby(['meta.credit_pos', 'meta.gender']).size().unstack(fill_value=0)\n",
    "\n",
    "print(posCredit_gender_counts)\n",
    "\n",
    "posCredit_gender_counts.plot(kind='bar', figsize=(10, 6), color=['blue', 'pink'])\n",
    "plt.title('Count of Characters by posCredit and Gender')\n",
    "plt.xlabel('posCredit')\n",
    "plt.ylabel('Count of Characters')\n",
    "plt.legend(title='Gender')\n",
    "plt.xticks(rotation=0)  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the ratings\n",
    "plt.figure(figsize=(30, 15))\n",
    "sns.histplot(final_df['meta.rating'], bins=20, kde=True)\n",
    "plt.title('Distribution of Movie Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the frequences\n",
    "conversation_lengths = final_df['conversation_id'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.histplot(conversation_lengths, bins=30, kde=True)\n",
    "plt.title('Distribution of Conversation Lengths')\n",
    "plt.xlabel('Number of Utterances per Conversation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplotting the numerical features\n",
    "sns.pairplot(final_df[['line_count', 'lineLength',\t'wordCountLine']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "final_df['gender_encoded'] = label_encoder.fit_transform(final_df['meta.gender'])\n",
    "\n",
    "category_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update([',', '.', '?', ':', ';', \"'\", '“', '”', '!', '’', '...', '....', '--', '_'])\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['processed_text'] = final_df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre - Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text\n",
    "vectorizer = TfidfVectorizer(max_features=5000) \n",
    "X_text = vectorizer.fit_transform(final_df['processed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "final_df['gender_label'] = le.fit_transform(final_df['meta.gender'])\n",
    "y = final_df['gender_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_pos_encoder = LabelEncoder()\n",
    "final_df['encoded_credit_pos'] = credit_pos_encoder.fit_transform(final_df['meta.credit_pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X_other = final_df[['line_count', 'encoded_credit_pos', 'medianLineLength', 'medianWordCountLine']]\n",
    "\n",
    "X_other_sparse = csr_matrix(X_other.values)\n",
    "X_combined = hstack([X_text, X_other_sparse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "start_time = time.time()\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "nb_y_pred = nb_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, nb_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total Execution Time: {total_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000) \n",
    "X_text_1 = vectorizer.fit_transform(final_df['processed_text'])\n",
    "\n",
    "binarizer = Binarizer()\n",
    "X_binary = binarizer.fit_transform(X_text_1.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_other_1 = final_df[['line_count', 'encoded_credit_pos', 'medianLineLength', 'medianWordCountLine']]\n",
    "\n",
    "X_other_sparse_1 = csr_matrix(X_other_1.values)\n",
    "X_combined_1 = hstack([X_text_1, X_other_sparse_1])\n",
    "\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_combined_1, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli Naive Bayes Classifier\n",
    "start_time = time.time()\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred = bnb.predict(X_test_1)\n",
    "\n",
    "accuracy = accuracy_score(y_test_1, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total Execution Time: {total_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loogistic Regression Classifier\n",
    "start_time = time.time()\n",
    "\n",
    "lr_clr = LogisticRegression(solver = 'lbfgs', n_jobs=-1) \n",
    "lr_clr.fit(X_train, y_train)\n",
    "\n",
    "lr_y_pred = lr_clr.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, lr_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total Execution Time: {total_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "start_time = time.time()\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total Execution Time: {total_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "nb_scores = cross_val_score(nb_clf, X_combined, y, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation scores for Multinomial Naive Bayes:\", nb_scores)\n",
    "print(\"Mean accuracy:\", nb_scores.mean())\n",
    "\n",
    "bnb_scores = cross_val_score(bnb, X_combined_1, y, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation scores for Bernoulli Naive Bayes:\", bnb_scores)\n",
    "print(\"Mean accuracy:\", bnb_scores.mean())\n",
    "\n",
    "lr_scores = cross_val_score(lr_clr, X_combined, y, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation scores for Logistic Regression:\", lr_scores)\n",
    "print(\"Mean accuracy:\", lr_scores.mean())\n",
    "\n",
    "rf_scores = cross_val_score(rf, X_combined, y, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation scores for Random Forest:\", rf_scores)\n",
    "print(\"Mean accuracy:\", rf_scores.mean())\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 6), nb_scores, label='Multinomial Naive Bayes', marker='o')\n",
    "plt.plot(range(1, 6), bnb_scores, label='Bernoulli Naive Bayes', marker='o')\n",
    "plt.plot(range(1, 6), lr_scores, label='Logistic Regression', marker='o')\n",
    "plt.plot(range(1, 6), rf_scores, label='Random Forest', marker='o')\n",
    "plt.title('Cross-validation Scores')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the cross-validation scores\n",
    "all_scores = [nb_scores, bnb_scores, lr_scores, rf_scores]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(all_scores, labels=['Multinomial Naive Bayes', 'Bernoulli Naive Bayes', 'Logistic Regression', 'Random Forest'])\n",
    "plt.title('Cross-validation Scores')\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
